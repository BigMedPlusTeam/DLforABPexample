{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"![](http://)UNET training with a \"fixed\" dataset (PLETH to ABP)(MAE)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import necessary libraries\n\nimport numpy as np\nimport os\nimport pickle\nimport wfdb\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport time\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dda652b6d60e15fe6a43ece670f380531739fdaa"},"cell_type":"code","source":"# Device for training -> CPU or GPU\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda:\"+str(torch.cuda.current_device()))\n    print(\"GPU available\")\n    print(\"Device:\",torch.cuda.current_device())\n    print(\"Model:\",torch.cuda.get_device_name(torch.cuda.current_device()))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU doesn't available\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf0acee706d1559f988a0bde08a2ae290af71948"},"cell_type":"code","source":"# Set NumPy and PyTorch seeds for reproducibility\n\nseed = 1234\n\n## Set Numpy seed\nnp.random.seed(seed)\n\n## Set Pytorch seed\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bbf1eaef7a0fe9ace723f3ccdd0f239bf100de0"},"cell_type":"code","source":"# Path\n\npath_train = \"../input/trainset/trainset\"\npath_val = \"../input/valset/valset\"\npath_test = \"../input/testset/testset\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5f76ed134f47ddf8bcf7a8cf3575c55c657fd13"},"cell_type":"code","source":"# Records info\n\ntrain_records = os.listdir(path_train)\ntrain_records.sort() # inplace\nprint('Number of train records: ' + str(len(train_records)))\n\nval_records = os.listdir(path_val)\nval_records.sort() # inplace\nprint('Number of validation records: ' + str(len(val_records)))\n\ntest_records = os.listdir(path_test)\ntest_records.sort() # inplace\nprint('Number of test records: ' + str(len(test_records)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9da5b30fbbd160191f5788006863a07eca994b71"},"cell_type":"code","source":"# Define the class to select randomly a record (ABP and PLETH signals)\n\nclass SelectRecord(torch.utils.data.Dataset):\n    \n    def __init__(self, path, num_samples=500, random=True):\n        self.path = path\n        self.num_samples = num_samples # number of samples per signal\n        self.random = random\n        self.list_files = os.listdir(path)\n        self.list_files.sort()\n        \n    ## Override to give PyTorch size of dataset\n    def __len__(self):\n        return len(self.list_files)\n                                                  \n    ## Override to give PyTorch access to any image on the dataset\n    def __getitem__(self, index):\n        \n        with open(self.path + '/' + self.list_files[index],'rb') as file:\n            dictt = pickle.load(file)\n        \n        X_ = dictt['pleth'][0] # numpy array\n        Y_ = dictt['abp'][0] # numpy array\n        \n        if self.random:\n            pos = np.random.randint(0, high=(len(dictt['pleth'][0])-(20*self.num_samples)))\n             \n        else:\n            pos = 0\n            \n        while True:\n            X = X_[pos:pos+self.num_samples]\n            Y = Y_[pos:pos+self.num_samples]\n            if not(np.any(np.isnan(X))) and not(np.any(np.isnan(Y))):\n                break\n            else:\n                pos += int(self.num_samples/3)\n                \n        return (torch.from_numpy(X).type(torch.FloatTensor).unsqueeze_(0), torch.from_numpy(Y).type(torch.FloatTensor).unsqueeze_(0)) # return float tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b795ad90fa576642503e9bc05e55a950822a1e9"},"cell_type":"code","source":"# Define variables\n\nnum_samples = 250 # number of samples per signal\nbatch_size = 256\nepochs = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6792435c424190ced1caa10d9d43be03138718bf"},"cell_type":"code","source":"# Load the training and validation dataset\n\ntrainset = SelectRecord(path_train, num_samples, False)\nvalset = SelectRecord(path_val, num_samples, False)\ntestset = SelectRecord(path_test, num_samples, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86308a0cde463b8b1bac6c60a6e44f4a388e5cf9"},"cell_type":"code","source":"k = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e07c4aad668aac1f2db280e9070851f42d183a12"},"cell_type":"code","source":"# Display (run several times this cell to display different signals)\n\nprint(k)\n\n## Training set\nsignal_train, targets_train = trainset[k]\n\nplt.figure(1)\nplt.plot(signal_train[0,:].numpy(), 'b', label='PLETH')\nplt.legend(loc='upper right')\nplt.show()\n\nplt.figure(2)\nplt.plot(targets_train[0,:].numpy(), 'g', label='ABP')\nplt.legend(loc='upper right')\nplt.show()\n\n## Validation set\nsignal_val, targets_val = valset[k]\n\nplt.figure(1)\nplt.plot(signal_val[0,:].numpy(), 'b', label='PLETH')\nplt.legend(loc='upper right')\nplt.show()\n\nplt.figure(2)\nplt.plot(targets_val[0,:].numpy(), 'g', label='ABP')\nplt.legend(loc='upper right')\nplt.show()\n\n## Test set\nsignal_test, targets_test = testset[k]\n\nplt.figure(1)\nplt.plot(signal_test[0,:].numpy(), 'b', label='PLETH')\nplt.legend(loc='upper right')\nplt.show()\n\nplt.figure(2)\nplt.plot(targets_test[0,:].numpy(), 'g', label='ABP')\nplt.legend(loc='upper right')\nplt.show()\n\nk += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae7525a8ad14d9d0840fe73fbe037d8f7f3de11c"},"cell_type":"code","source":"# Create the dataset loader\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\nvalloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0129f662b3eed46a49d704784a644e9a89b5fcba"},"cell_type":"code","source":"# Define the Convolutional Neural Network\n\nclass Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        ## Hidden layers\n        self.conv1 = nn.Conv1d(1, 32, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv2 = nn.Conv1d(32, 64, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv3 = nn.Conv1d(64, 128, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv4 = nn.Conv1d(128, 256, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv5 = nn.Conv1d(256, 512, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv6 = nn.Conv1d(512, 1024, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv7 = nn.Conv1d(1024, 2048, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv8 = nn.Conv1d(2048, 1024, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv9 = nn.Conv1d(1024+1024, 512, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv10 = nn.Conv1d(512+512, 256, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv11 = nn.Conv1d(256+256, 128, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv12 = nn.Conv1d(128+128, 64, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv13 = nn.Conv1d(64+64, 32, 3, stride=1, padding=1) # \"same\" convolution\n        self.conv14 = nn.Conv1d(32+32, 1, 3, stride=1, padding=1) # \"same\" convolution\n        \n        ## Batch normalization layers\n        self.bn1 = nn.BatchNorm1d(32)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.bn4 = nn.BatchNorm1d(256)\n        self.bn5 = nn.BatchNorm1d(512)\n        self.bn6 = nn.BatchNorm1d(1024)\n        self.bn7 = nn.BatchNorm1d(2048)\n        self.bn8 = nn.BatchNorm1d(1024)\n        self.bn9 = nn.BatchNorm1d(512)\n        self.bn10 = nn.BatchNorm1d(256)\n        self.bn11 = nn.BatchNorm1d(128)\n        self.bn12 = nn.BatchNorm1d(64)\n        self.bn13 = nn.BatchNorm1d(32)\n    \n        ## Dropout layer with drop probability\n        self.dropout = nn.Dropout(p=0.2)\n\n    def forward(self, x):\n    \n        x1 = self.conv1(x)\n        x1 = self.bn1(x1)\n        x1 = F.relu(x1)\n        x1 = self.dropout(x1)\n    \n        x2 = self.conv2(x1)\n        x2 = self.bn2(x2)\n        x2 = F.relu(x2)\n        x2 = self.dropout(x2)\n    \n        x3 = self.conv3(x2)\n        x3 = self.bn3(x3)\n        x3 = F.relu(x3)\n        x3 = self.dropout(x3)\n    \n        x4 = self.conv4(x3)\n        x4 = self.bn4(x4)\n        x4 = F.relu(x4)\n        x4 = self.dropout(x4)\n    \n        x5 = self.conv5(x4)\n        x5 = self.bn5(x5)\n        x5 = F.relu(x5)\n        x5 = self.dropout(x5)\n    \n        x6 = self.conv6(x5)\n        x6 = self.bn6(x6)\n        x6 = F.relu(x6)\n        x6 = self.dropout(x6)\n        \n        x7 = self.conv7(x6)\n        x7 = self.bn7(x7)\n        x7 = F.relu(x7)\n        x7 = self.dropout(x7)\n        \n        x8 = self.conv8(x7)\n        x8 = self.bn8(x8)\n        x8 = F.relu(x8)\n        x8 = self.dropout(x8)\n        \n        x9 = torch.cat([x6, x8], 1)\n        x9 = self.conv9(x9)\n        x9 = self.bn9(x9)\n        x9 = F.relu(x9)\n        x9 = self.dropout(x9)\n    \n        x10 = torch.cat([x5, x9], 1)\n        x10 = self.conv10(x10)\n        x10 = self.bn10(x10)\n        x10 = F.relu(x10)\n        x10 = self.dropout(x10)\n     \n        x11 = torch.cat([x4, x10], 1)\n        x11 = self.conv11(x11)\n        x11 = self.bn11(x11)\n        x11 = F.relu(x11)\n        x11 = self.dropout(x11)\n        \n        x12 = torch.cat([x3, x11], 1)\n        x12 = self.conv12(x12)\n        x12 = self.bn12(x12)\n        x12 = F.relu(x12)\n        x12 = self.dropout(x12)\n        \n        x13 = torch.cat([x2, x12], 1)\n        x13 = self.conv13(x13)\n        x13 = self.bn13(x13)\n        x13 = F.relu(x13)\n        x13 = self.dropout(x13)\n    \n        ## Output tensor\n        x14 = torch.cat([x1, x13], 1)\n        x14 = self.conv14(x14)\n\n        return x14","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52d3e233ef766c60fbf9d3c015ab0f0ec18b2725"},"cell_type":"code","source":"# Define the training process\n\ndef train_model(model, criterion, optimizer, traindataloader, valdataloader, epochs=5):\n\n    ## Initialize variables\n    training_time = 0\n    validation_time = 0\n    losses = []\n    losses_val = []\n  \n    ## Set model to train mode\n    model.train()\n\n    for epoch in range(epochs):\n    \n        ## Print current epoch\n        print('-' * 10)\n        print('Epoch {}/{}'.format(epoch, epochs - 1))\n\n        ## Initialize variables\n        loss_epoch = 0\n        loss_val_epoch = 0\n    \n        ## Start training time\n        since0 = time.time()\n\n        for signals, targets in traindataloader:    \n      \n            ## Send input tensors to device \n            signals = signals.to(device)\n            targets = targets.to(device)\n\n            ## Clear the gradients, do this because gradients are accumulated\n            optimizer.zero_grad()\n\n            ## Forward pass\n            output = model(signals)\n\n            ## Calculate the loss\n            loss = criterion(output, targets)\n\n            ## Backward pass\n            loss.backward()\n\n            ## Update weights\n            optimizer.step()\n\n            ## Accumulate loss of each batch of the epoch\n            loss_epoch += loss.item()\n            \n            print('#', end = '')\n\n        ## Append mean loss in each epoch\n        losses.append(loss_epoch/len(traindataloader)) # len(traindataloader) = number of batches in traindataloader\n    \n        ## Print mean loss in each epoch\n        print('Loss: {}'.format(loss_epoch/len(traindataloader))) # len(traindataloader) = number of batches in traindataloader\n    \n        ## Print training time in each epoch\n        time_epoch = time.time() - since0\n        print('Time: {:.0f}m {:.1f}s'.format(time_epoch // 60, time_epoch % 60))\n\n        ## Accumulate training epoch time\n        training_time += time_epoch\n\n    ########################################## Validation ####################################\n    \n        ## Start validation time\n        since1 = time.time()\n\n        ## Turn off gradients for validation, saves memory and computations\n        with torch.no_grad():\n      \n            ## Set model to evaluation mode (dropout probability is 0 and BatchNorm)\n            model.eval()\n\n            for signals_val, targets_val in valdataloader:\n                signals_val = signals_val.to(device)\n                targets_val = targets_val.to(device)\n                output_val = model(signals_val)\n                loss_val = criterion(output_val, targets_val)\n                loss_val_epoch += loss_val.item()\n                print('#', end = '')\n\n        ## Append mean loss in each epoch\n        losses_val.append(loss_val_epoch/len(valdataloader)) # len(valdataloader) = number of batches in valdataloader\n    \n        ## Print mean loss in each epoch\n        print('Validation loss: {}'.format(loss_val_epoch/len(valdataloader))) # len(valdataloader) = number of batches in valdataloader\n\n        ## Print training time the epoch\n        time_val_epoch = time.time() - since1\n        print('Validation time: {:.0f}m {:.1f}s'.format(time_val_epoch // 60, time_val_epoch % 60))\n\n        ## Accumulate validation epoch time\n        validation_time += time_val_epoch\n\n        ## Set model back to train mode\n        model.train()\n    ##########################################################################################\n\n    ## Transform lists in NumPy arrays\n    losses = np.array(losses)\n    losses_val = np.array(losses_val)\n  \n    ## Print elapsed training time in all the epochs\n    print('-' * 20)\n    print('Total training time: {:.0f}m {:.1f}s'.format(training_time // 60, training_time % 60))\n    print('Total validation time: {:.0f}m {:.1f}s'.format(validation_time // 60, validation_time % 60))\n    print('Total  time: {:.0f}m {:.1f}s'.format((training_time + validation_time) // 60, (training_time + validation_time) % 60))\n  \n    ## Display training process (losses)\n    plt.plot(losses, 'b', label='Training loss')\n    plt.plot(losses_val, 'g', label='Validation loss')\n    plt.legend(loc='upper right')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.show()\n  \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46b590156875b9c1aaf4135110f2de8d6d66aa7b"},"cell_type":"code","source":"# Execution\n\n## Create the model    \nmodel = Network()\nmodel = model.to(device) \n\n## Define loss function\n#criterion = nn.MSELoss()\ncriterion = nn.L1Loss()\n\n## Define optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n\n## Train the model\nmodel = train_model(model, criterion, optimizer, trainloader, valloader, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"148ac99d4525520a3bc11f82306b2f81b73b36f8"},"cell_type":"code","source":"# Prediction\n\n## Send model to CPU for prediction\nmodel = model.to(\"cpu\")\n\n## Set model to evaluation mode\nmodel.eval()\n\n## Create the dataset loader\ntestloader = torch.utils.data.DataLoader(testset, batch_size=len(test_records), shuffle=False)\n\nsignals_test, targets_test = next(iter(testloader))\n\n\n## Send input tensors to device \nsignals_test = signals_test.to(\"cpu\")\ntargets_test = targets_test.to(\"cpu\")\n\n## Turn off gradients to speed up this part\nwith torch.no_grad():\n    prediction = model(signals_test)\n\n## Accuracy\nmse = criterion(prediction, targets_test)\nprint(mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af296a1c6cfb2933455a02d454f6d90541b9e7f5"},"cell_type":"code","source":"# Display \n\ni = np.random.randint(0, high=len(test_records))\ni = 236\n\nprint(i)\n\nplt.figure(1, figsize=(8, 6))\nplt.plot(signals_test[i,0,:].numpy(), 'b', label='PLETH')\nplt.legend(loc='upper right')\nplt.show()\n\n\nplt.figure(2, figsize=(8, 6))\nplt.plot(targets_test[i,0,:].numpy(), 'g', label='ABP')\nplt.plot(prediction[i,0,:].numpy(), 'r', label='Predicted ABP')\nplt.legend(loc='upper right')\nplt.show()\n\ni += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d42f7ae93bbc7fa63eef070f6eb9c8e387636bb"},"cell_type":"code","source":"plt.figure(1, figsize=(15, 12))\n\nplt.subplot(2, 2, 1)\nplt.plot(signals_test[236,0,:].numpy(), 'b', label='PLETH')\nplt.legend(loc='upper left', prop={'size': 8})\nplt.xlabel('Samples')\nplt.ylabel('mV')\nplt.title('PLETH to ABP')\nplt.xlim(0, 250)\nplt.ylim(-0.6, 0.6)\nplt.grid(True)\n\nplt.subplot(2, 2, 2)\nplt.plot(targets_test[236,0,:].numpy(), 'g', label='ABP')\nplt.plot(prediction[236,0,:].numpy(), 'r', label='Pred. ABP')\nplt.legend(loc='upper left', prop={'size': 8})\nplt.xlabel('Samples')\nplt.ylabel('mmHg')\nplt.title('PLETH to ABP')\nplt.xlim(0, 250)\nplt.ylim(50, 140)\nplt.grid(True)\n\nplt.subplot(2, 2, 3)\nplt.plot(signals_test[490,0,:].numpy(), 'b', label='PLETH')\nplt.legend(loc='upper left', prop={'size': 8})\nplt.xlabel('Samples')\nplt.ylabel('mV')\nplt.title('PLETH to ABP')\nplt.xlim(0, 250)\nplt.ylim(-0.6, 0.6)\nplt.grid(True)\n\nplt.subplot(2, 2, 4)\nplt.plot(targets_test[490,0,:].numpy(), 'g', label='ABP')\nplt.plot(prediction[490,0,:].numpy(), 'r', label='Pred. ABP')\nplt.legend(loc='upper left', prop={'size': 8})\nplt.xlabel('Samples')\nplt.ylabel('mmHg')\nplt.title('PLETH to ABP')\nplt.xlim(0, 250)\nplt.ylim(50, 140)\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}